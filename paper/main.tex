\documentclass[10pt,twocolumn]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage[margin=0.75in]{geometry}
\setlength{\columnsep}{0.25in}

\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}

\usepackage{booktabs}
\usepackage{array}
\usepackage{enumitem}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{url}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[numbers,sort&compress]{natbib}

\usepackage{listings}
\usepackage{xcolor}
\lstset{
  basicstyle=\ttfamily\footnotesize,
  breaklines=true,
  frame=single,
  columns=fullflexible,
  keepspaces=true
}

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.0ex plus 0.2ex minus 0.2ex}{0.6ex}
\titlespacing*{\subsection}{0pt}{0.9ex plus 0.2ex minus 0.2ex}{0.4ex}
\titlespacing*{\subsubsection}{0pt}{0.7ex plus 0.2ex minus 0.2ex}{0.2ex}

\newtheorem{definition}{Definition}

\newcommand{\CP}{\mathrm{CP}}
\newcommand{\Host}{\mathrm{H}}
\newcommand{\RS}{\mathrm{RS}}
\newcommand{\Aset}{\mathcal{A}}
\newcommand{\Wset}{\mathcal{W}}
\newcommand{\Vset}{\mathcal{V}}
\newcommand{\Pass}{\textsf{PASS}}
\newcommand{\Fail}{\textsf{FAIL}}
\newcommand{\Incon}{\textsf{INCONCLUSIVE}}
\newcommand{\Replay}{\textsf{REPLAY}}
\newcommand{\Cross}{\textsf{CROSSCHECK}}
\newcommand{\Heur}{\textsf{HEURISTIC}}

\newcommand{\Rvec}{\mathbf{R}}
\newcommand{\pvec}{\mathbf{p}}
\newcommand{\Cmat}{\mathbf{C}}
\newcommand{\Mmat}{\mathbf{M}}

\newcommand{\alphaD}{\alpha}
\newcommand{\tauT}{\tau}

\title{\bfseries ExecutionRank: Verified Multi-Agent Execution via Weighted Attestation and Threshold Acceptance}
\author{Nikko Ambroselli}
\date{February 14, 2026}

\begin{document}

\twocolumn[
\begin{@twocolumnfalse}
\maketitle

\begin{abstract}
Autonomous agent systems increasingly delegate tool invocation to remote agents discovered through registries.
While this enables scale and specialization, it introduces a missing primitive: \emph{verifiable execution trust}.
Most systems accept a tool's return value as evidence of correctness or rely on an LLM to judge outputs, neither of which
constitutes independent verification. We present \emph{ExecutionRank}, a trust layer for autonomous tool invocation that combines
(i) verified multi-agent execution (worker + independent verifiers), (ii) a weighted attestation graph built from auditable positive attestations,
and (iii) deterministic threshold acceptance to gate consumption of results (and optionally, authorization of side effects).
ExecutionRank yields a policy-tunable assurance signal for tool calls under uncertainty.
\end{abstract}

\vspace{0.75em}
\noindent\textbf{Keywords:} autonomous agents; tool invocation; verification; attestation; reputation; EigenTrust; risk gating; audit receipts.
\vspace{1.0em}
\end{@twocolumnfalse}
]

\section{Problem Context}
Autonomous agent systems increasingly delegate tool invocation to remote agents discovered via registries (e.g., ERC-8004).
A host (\Host, e.g., LLM, orchestrator, or user client) selects an agent, invokes a tool, and consumes the result.
This model lacks verifiable execution trust.

\paragraph{Unverified execution.}
Current systems treat successful tool return as sufficient evidence of correctness.
There is no independent attestation that the output matches the intended computation.
A malicious or faulty worker can return arbitrary data; the host has no mechanism to distinguish valid from invalid results short of re-executing the task itself.

\paragraph{LLM-as-judge insufficiency.}
Using the invoking LLM to judge its own tool outputs creates a single point of trust.
The LLM has no access to ground truth; it can only perform semantic plausibility checks.
Such checks are subjective, non-reproducible, and vulnerable to prompt injection or model bias.
They do not constitute independent verification.

\paragraph{Absence of independent attestation.}
In traditional distributed systems, Byzantine fault tolerance relies on multiple independent replicas or witnesses.
Agent tool invocation typically has no such witnesses: the worker runs once, and the result is accepted or rejected by the invoker alone.

\paragraph{Risk of unverified invocation.}
Tools may have side effects (payments, state changes, external API calls).
Accepting unverified results exposes systems to incorrect state, financial loss, and cascading failures.
Policy gates reduce which agents may be invoked but do not verify that a specific invocation produced a correct result.

ExecutionRank introduces a control plane that (1) runs a worker and multiple independent verifiers,
(2) builds a weighted attestation graph from \Pass attestations, and (3) gates acceptance on a reputation-weighted threshold.

\section{Verified Multi-Agent Execution}
Execution is structured around three roles:

\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
Role & Identity & Responsibility \\
\midrule
Worker ($W$) & Agent ID & Executes the tool and produces outputs \\
Verifier ($V$) & Agent ID & Independently validates outputs \\
Invoker ($I$) & Principal & Consumes result; may attest semantic correctness \\
\bottomrule
\end{tabular}
\caption{Roles in verified execution.}
\label{tab:roles}
\end{table}

\paragraph{Flow.}
The control plane runs the worker, selects $k$ verifiers (excluding the worker),
and invokes each verifier's \texttt{verify\_result} tool with
$\{ \mathrm{taskId}, \mathrm{workerAgentId}, \mathrm{workerTool}, \mathrm{argsHash}, \mathrm{outputHash} \}$.
Verifiers return $\{ \mathrm{verdict}, \mathrm{confidence}, \mathrm{mode} \}$.
All attestations are stored as verification receipts with role and verdict.

\paragraph{Verification modes (ordered by strength).}
\begin{itemize}[leftmargin=*]
  \item \Replay: re-execute the tool and compare outputs (strongest).
  \item \Cross: use alternative logic to validate correctness.
  \item \Heur: rule-based or approximate checks.
\end{itemize}

Only \Pass attestations contribute to the trust graph. \Fail and \Incon are recorded for audit but do not create edges.

\begin{algorithm*}[t]
\caption{VerifiedExecution (Control Plane)}
\label{alg:verified-exec}
\begin{algorithmic}[1]
\Require Worker $W$, tool $T$, args $x$, verifier count $k$, policy $\Pi$
\Ensure Decision \textsf{accepted}/\textsf{rejected}, receipts
\State $y \gets \CP.\textsf{Invoke}(W, T, x)$
\State $d_x \gets H(x)$; $d_y \gets H(y)$
\State $\Vset \gets \CP.\textsf{SelectVerifiers}(k, \Pi, \text{exclude}=W)$
\ForAll{$V \in \Vset$}
  \State $(v, c, m) \gets \CP.\textsf{Invoke}(V, \textsf{verify\_result}, \langle \mathrm{taskId}, W, T, d_x, d_y \rangle)$
  \State \CP.\textsf{AppendVerificationReceipt}$(V,W,T,d_x,d_y,v,c,m)$
\EndFor
\State \CP.\textsf{AppendExecutionReceipt}$(W,T,d_x,d_y)$
\State \Return \CP.\textsf{DecideAcceptance}$(\mathrm{taskId})$
\end{algorithmic}
\end{algorithm*}

\section{Weighted Attestation Graph}
\subsection{Graph Structure and Design Rationale}
The trust graph is bipartite: vertices are partitioned into attestors (verifiers + invokers) and workers.
Edges are directed attestor$\rightarrow$worker. Only \Pass attestations create edges.

\subsection{Edge Weight}
For an attestor $A$ attesting \Pass to worker $W$, define:
\begin{equation}
t(A,W) = \lambda_{\mathrm{role}} \cdot \mathrm{confidence} \cdot \mathrm{verificationStrength} \cdot \mathrm{agreementFactor} \cdot \mathrm{timeDecay}.
\end{equation}

\subsection{Normalized Matrix $C$}
Rows = attestors, columns = workers:
\begin{equation}
\Cmat_{A,W} = \frac{\max(t(A,W), 0)}{\sum_{W'} \max(t(A,W'), 0)}.
\label{eq:C}
\end{equation}

\subsection{Attestor--Attestor Flow Matrix $M$}
Let $\mathcal{A}$ be attestors ($|\mathcal{A}|=n$), $\mathcal{W}$ workers ($|\mathcal{W}|=m$), and $\Cmat\in\mathbb{R}^{n\times m}$ row-stochastic.
Define $s_w = \sum_{a\in\mathcal{A}} \Cmat_{a,w}$.
Define $Q_{w,b}=\Cmat_{b,w}/s_w$ if $s_w>0$ else $1/n$. Then $\Mmat=\Cmat Q=\Cmat D^{-1}\Cmat^\top$.

\subsection{EigenTrust-Style Ranking}
\begin{equation}
\Rvec = (1-\alphaD)\pvec + \alphaD \Mmat \Rvec.
\end{equation}

\section{Acceptance Threshold Logic}
\begin{definition}[Acceptance predicate]
\begin{equation}
\textsf{accepted} \iff \left( \sum_{A \in \mathcal{A}} R_A \ge \tauT \right) \land \left( |\mathcal{A}| \ge 1 \right).
\end{equation}
\end{definition}

\section{Security and Adversarial Considerations}
\section{Deployment and Integration Model}

\appendix
\section{Illustrative Receipt Schemas}
\subsection{Execution Receipt}
\begin{lstlisting}[language=json]
{"receipt_id":"uuid","task_id":"uuid","worker_agent_id":"agent:12345"}
\end{lstlisting}

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}
